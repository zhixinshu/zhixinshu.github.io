<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <title>Zhixin Shu</title>
	<meta name="description" content="Zhixin Shu's Homepage">
    <meta name="author" content="Zhixin Shu">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link href="./style_files/bootstrap.min.css" type="text/css" rel="stylesheet">
	<link href="./style_files/custom.css" type="text/css" rel="stylesheet">
    
</head>

<!-- Body. -->
<body>

<div class="container">
<h1>Zhixin Shu</h1>
</div>
 
 <div class="container anchor" id="Top"> 
	<div class="row row-offcanvas row-offcanvas-right">
		<div class="col-lg-3 col-md-3 col-sm-4">
			<img width="192px" src="./image/zhixin_0.jpg" class="img-responsive" style="border:0px solid #000000" alt="Zhixin Shu">
		</div>
		<div class="col-lg-4 col-md-4 col-sm-4">
			<big>
			<p>Address: 345 Park Ave, San Jose, CA 95110</p>
			<p>Email: zshu AT adobe DOT com</p>
			<p><a href="https://www.linkedin.com/in/zhixin-shu-aa6aa57a"> LinkedIn </a></p>
			<p><a href="https://scholar.google.com/citations?user=gp6HUP0AAAAJ&hl=en"> Google Scholar </a></p>
			<p><a href="./cv/cv_zhixinshu.pdf">CV</a></p>
			</big><br>
		</div>
	</div>
		<h5><i>Photo courtesy of Dimitris Samaras</i></h5>

	<br>
 </div>
 
 <div class="container section-anchor" id="Bio">
	<h2>About</h2>
	<p>
	I'm a research scientist at <a href="https://research.adobe.com/">Adobe Research</a>.
	Between 2013 to 2019, I was a PhD student at  <a href="http://www.stonybrook.edu/">Stony Brook University</a> advised by Professor <a href="http://www3.cs.stonybrook.edu/~samaras/">Dimitris Samaras</a>.
	</p>

	<p>
	I'm interested in research topics related to <b>humans</b> in the intersection of computer vision, computer graphics, and machine learning. My recent work has a focus on <b>human face</b>-centered problems, including controllable generation, 3D modeling & capturing, neural rendering, and editing. 
	</p>

	<p>
	Feel free to email me if you are interested in my work, have exciting ideas to chat about and collaborate on, or if you are interested in <a href="https://research.adobe.com/internships/">research internships at Adobe</a>.
	<p>

</div>

<div class="container section-anchor" id="Research">
	<h2>Publications</h2>

	<!-- isofurface -->
	<div class="publication">
		<div class="thumb"><a href="./image/isosurface.png"><img src="./image/isosurface.png"></a>&nbsp;</div>
		<div class="title"><a href="./image/comingsoon.jpg">Learning an Isometric Surface Parameterization for Texture Unwrapping</a></div>
		<div class="authors">
		Sagnik Das,
		Ke Ma,
		Zhixin Shu,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>ECCV 2022 </em>
		</div>
		<div class="cite">
		[<a href="./image/comingsoon.jpg">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- 3DFMGAN -->
	<div class="publication">
		<div class="thumb"><a href="./image/3dfmgan.png"><img src="./image/3dfmgan.png"></a>&nbsp;</div>
		<div class="title"><a href="./image/comingsoon.jpg">3D-FM GAN: Towards 3D-Controllable Face Manipulation</a></div>
		<div class="authors">
		Yuchen Liu, 
		Zhixin Shu, 
		Yijun Li, 
		Zhe Lin, 
		Richard Zhang, 
		S.Y. Kung
		</div>
		<div class="venue">
		<em>ECCV 2022 </em>
		</div>
		<div class="cite">
		[<a href="./image/comingsoon.jpg">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->


	<!-- paperedge -->
	<div class="publication">
		<div class="thumb"><a href="./image/paperedge.png"><img src="./image/paperedge.png"></a>&nbsp;</div>
		<div class="title"><a href="./pdf/SIGGRAPH_22_PAPEREDGE.pdf">Learning From Documents in the Wild to Improve Document Unwarping</a></div>
		<div class="authors">
		Ke Ma,
		Sagnik Das,
		Zhixin Shu,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>SIGGRAPH 2022 </em>
		</div>
		<div class="cite">
		[<a href="./pdf/SIGGRAPH_22_PAPEREDGE.pdf">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- rignerf -->
	<div class="publication">
		<div class="thumb"><a href="http://shahrukhathar.github.io/2022/06/06/RigNeRF.html"><img src="./image/rignerf.png"></a>&nbsp;</div>
		<div class="title"><a href="http://shahrukhathar.github.io/2022/06/06/RigNeRF.html">RigNeRF: Fully Controllable Neural 3D Portraits</a></div>
		<div class="authors">
		ShahRukh Athar, 
		Zexiang Xu, 
		Kalyan Sunkavalli, 
		Eli Shechtman, 
		Zhixin Shu
		</div>
		<div class="venue">
		<em>CVPR 2022 </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/abs/2206.06481">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- yoon2022 -->
	<div class="publication">
		<div class="thumb"><a href="https://www-users.cse.umn.edu/~jsyoon/Motion_learning/"><img src="./image/yoon22.svg"></a>&nbsp;</div>
		<div class="title"><a href="https://www-users.cse.umn.edu/~jsyoon/Motion_learning/">Learning Motion-Dependent Appearance for High-Fidelity Rendering of Dynamic Humans from a Single Camera</a></div>
		<div class="authors">
		Jae Shin Yoon, 
		Duygu Ceylan, 
		Tuanfeng Y. Wang, 
		Jingwan Lu, 
		Jimei Yang, 
		Zhixin Shu, 
		Hyun Soo Park
		</div>
		<div class="venue">
		<em>CVPR 2022 </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/pdf/2203.12780.pdf">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->



	<!-- pointnerf  -->
	<div class="publication">
		<div class="thumb"><a href="https://xharlie.github.io/projects/project_sites/pointnerf/"><img src="./image/pointnerf.png"></a>&nbsp;</div>
		<div class="title"><a href="https://xharlie.github.io/projects/project_sites/pointnerf/">Point-NeRF: Point-based Neural Radiance Fields</a></div>
		<div class="authors">
		Qiangeng Xu, 
		Zexiang Xu, 
		Julien Philip, 
		Sai Bi, 
		Zhixin Shu, 
		Kalyan Sunkavalli, 
		Ulrich Neumann
		</div>
		<div class="venue">
		<em>CVPR 2022 (oral) </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/pdf/2201.08845.pdf">paper</a>][<a href="hsttps://xharlie.github.io/projects/project_sites/pointnerf/">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->


	<!-- videorelit  -->
	<div class="publication">
		<div class="thumb"><a href="https://openaccess.thecvf.com/content/WACV2022W/WACI/papers/Chandran_Temporally_Consistent_Relighting_for_Portrait_Videos_WACVW_2022_paper.pdf"><img src="./image/videorelit.png"></a>&nbsp;</div>
		<div class="title"><a href="https://openaccess.thecvf.com/content/WACV2022W/WACI/papers/Chandran_Temporally_Consistent_Relighting_for_Portrait_Videos_WACVW_2022_paper.pdf">Temporally Consistent Relighting for Portrait Videos</a></div>
		<div class="authors">
		Sreenithy Chandran,
		Yannick Hold-Geoffroy,
		Kalyan Sunkavalli,
		Zhixin Shu,
		Suren Jayasuriya
		</div>
		<div class="venue">
		<em>WACV 2021 </em>
		</div>
		<div class="cite">
		[<a href="https://openaccess.thecvf.com/content/WACV2022W/WACI/papers/Chandran_Temporally_Consistent_Relighting_for_Portrait_Videos_WACVW_2022_paper.pdf">paper</a>][<a href="https://openaccess.thecvf.com/content/WACV2022W/WACI/html/Chandran_Temporally_Consistent_Relighting_for_Portrait_Videos_WACVW_2022_paper.html#:~:text=supp%5D%20%5B-,bibtex,-%5D">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- posewithstyle  -->
	<div class="publication">
		<div class="thumb"><a href="https://pose-with-style.github.io/"><img src="./image/posewithstyle_teaser.png"></a>&nbsp;</div>
		<div class="title"><a href="https://pose-with-style.github.io/">Pose with Style: Detail-Preserving Pose-Guided Image Synthesis with Conditional StyleGAN</a></div>
		<div class="authors">
		Badour AlBahar,
		Jingwan Lu,
		Jimei Yang,
		Zhixin Shu,
		Eli Shechtman,
		Jia-Bin Huang
		</div>
		<div class="venue">
		<em>SIGGRAPH Asia (TOG) 2021 </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/abs/2109.06166">paper</a>][<a href="./txt/posewithstyle.bib">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- human relighting  -->
	<div class="publication">
		<div class="thumb"><a href="http://giga.cps.unizar.es/~mlagunas/publication/human-relighting/"><img src="./image/humanrelit.png"></a>&nbsp;</div>
		<div class="title"><a href="http://giga.cps.unizar.es/~mlagunas/publication/human-relighting/">Single-image Full-body Human Relighting</a></div>
		<div class="authors">
		Manuel Lagunas,
		Xin Sun,
		Jimei Yang,
		Ruben Villegas,
		Jianming Zhang,
		Zhixin Shu,
		Belen Masia,
		Diego Gutierrez
		</div>
		<div class="venue">
		<em>EGSR 2021 </em>
		</div>
		<div class="cite">
		[<a href="http://giga.cps.unizar.es/~mlagunas/papers/2021-EGSR-lagunas-relighting.pdf">paper</a>][<a href="http://giga.cps.unizar.es/~mlagunas/bibs/relighting_egsr_21.html">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->


	<!-- project GANcompression  -->
	<div class="publication">
		<div class="thumb"><a href="https://lychenyoko.github.io/content_aware_gan_compression/"><img src="./image/compression.png"></a>&nbsp;</div>
		<div class="title"><a href="https://lychenyoko.github.io/content_aware_gan_compression/">Content-Aware GAN Compression</a></div>
		<div class="authors">
		Yuchen Liu,
		Zhixin Shu,
		Yijun Li,
		Zhe Lin,
		Federico Perazzi,
		S.Y. Kung
		</div>
		<div class="venue">
		<em>CVPR 2021 </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/abs/2104.02244">paper</a>][<a href="https://lychenyoko.github.io/content_aware_gan_compression/assets/bibtex.txt">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project DefGAN  -->
	<div class="publication">
		<div class="thumb"><a href="https://arxiv.org/pdf/1911.00735.pdf"><img src="./image/defgan.png"></a>&nbsp;</div>
		<div class="title"><a href="https://arxiv.org/pdf/1911.00735.pdf">Self-supervised Deformation Modeling for Facial Expression Editing</a></div>
		<div class="authors">
		ShahRukh Athar,
		Zhixin Shu,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>FG 2020</em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/pdf/1911.00735.pdf">paper</a>][<a href="https://www.computer.org/csdl/api/v1/citation/bibtex/proceedings/1kecGUxjQC4/307900a725">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project 3Dface  -->
	<div class="publication">
		<div class="thumb"><a href="./pdf/FG_2020_3D_Face_Reconstruction.pdf"><img src="./image/face3d.png"></a>&nbsp;</div>
		<div class="title"><a href="./pdf/FG_2020_3D_Face_Reconstruction.pdf">Learning Monocular Face Reconstruction using Multi-View Supervision</a></div>
		<div class="authors">
		Zhixin Shu,
		Duygu Ceylan,
		Kalyan Sunkavalli,
		Eli Shechtman,
		Sunil Hadap,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>FG 2020 (best paper runner up) </em>
		</div>
		<div class="cite">
		[<a href="./pdf/FG_2020_3D_Face_Reconstruction.pdf">paper</a>][<a href="https://www.computer.org/csdl/api/v1/citation/bibtex/proceedings/1kecGUxjQC4/307900a762">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->


	<!-- project dewarpnet  -->
	<div class="publication">
		<div class="thumb"><a href="https://www3.cs.stonybrook.edu/~cvl/content/papers/2019/SagnikKe_ICCV19.pdf"><img src="./image/Dewarpnet.jpg"></a>&nbsp;</div>
		<div class="title"><a href="https://www3.cs.stonybrook.edu/~cvl/content/papers/2019/SagnikKe_ICCV19.pdf">DewarpNet: Single-Image Document Unwarping with Stacked 3D and 2D Regression Networks</a></div>
		<div class="authors">
		Sagnik Das*,
		Ke Ma*,
		Zhixin Shu,
		Roy Shilrot,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>ICCV 2019 </em>
		</div>
		<div class="cite">
		[<a href="https://www3.cs.stonybrook.edu/~cvl/content/papers/2019/SagnikKe_ICCV19.pdf">paper</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project lae  -->
	<div class="publication">
		<div class="thumb"><a href="https://arxiv.org/abs/1904.11960"><img src="./image/lae.png"></a>&nbsp;</div>
		<div class="title"><a href="https://arxiv.org/abs/1904.11960">Lifting AutoEncoders: Unsupervised Learning of a Fully-Disentangled 3D Morphable Model using Deep Non-Rigid Structure from Motion</a></div>
		<div class="authors">
		Mihir Sahasrabudhe*,
		Zhixin Shu*,
		Edward Bartrum,
		Rıza Alp Güler,
		Dimitris Samaras,  
		Nikos Paragios,
		Iasonas Kokkinos 
		</div>
		<div class="venue">
		<em>ICCV Workshop 2019 </em>
		</div>
		<div class="cite">
		[<a href="https://arxiv.org/pdf/1904.11960.pdf">paper</a>][<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:DZeL6xpKJisJ:scholar.google.com/&output=citation&scisdr=CgUDi9JREI2arN14HxE:AAGBfm0AAAAAXTt9BxFSt50j1V38h9qJxgrLSgqAW-6i&scisig=AAGBfm0AAAAAXTt9B_2Nx8LlMQhfsKiM7T6ByC4wP2-G&scisf=4&ct=citation&cd=-1&hl=zh-CN">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project adv-ten  -->
	<div class="publication">
		<div class="thumb"><a href="https://link.springer.com/article/10.1007/s11263-019-01163-7"><img src="./image/advten.png"></a>&nbsp;</div>
		<div class="title"><a href="https://link.springer.com/article/10.1007/s11263-019-01163-7">An Adversarial Neuro-Tensorial Approach for Learning Disentangled Representations</a></div>
		<div class="authors">
		Mengjiao Wang, 
		Zhixin Shu, 
		Shiyang Cheng, 
		Yannis Panagakis, 
		Dimitris Samaras, 
		Stefanos Zafeiriou
		</div>
		<div class="venue">
		<em>IJCV 2019 </em>
		</div>
		<div class="cite">
		[<a href="https://link.springer.com/article/10.1007/s11263-019-01163-7">paper</a>][<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:vkd1PI5qhkgJ:scholar.google.com/&output=citation&scisdr=CgUDi9JREI2arN15a7Q:AAGBfm0AAAAAXTt8c7RoN7O4C9AnTysqKv7YqGIhoAv3&scisig=AAGBfm0AAAAAXTt8cwPZ7x3q34HpcXTznWL5dVncHKUn&scisf=4&ct=citation&cd=-1&hl=zh-CN">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project dae  -->
	<div class="publication">
		<div class="thumb"><a href="http://www3.cs.stonybrook.edu/~cvl/dae.html"><img src="./image/dae.png"></a>&nbsp;</div>
		<div class="title"><a href="http://www3.cs.stonybrook.edu/~cvl/dae.html">Deforming Autoencoders: Unsupervised Disentangling of Shape and Appearance</a></div>
		<div class="authors">
		Zhixin Shu,
		Mihir Sahasrabudhe,
		Rıza Alp Güler,
		Dimitris Samaras,  
		Nikos Paragios,
		Iasonas Kokkinos 
		</div>
		<div class="venue">
		<em>ECCV 2018 </em>
		</div>
		<div class="cite">
		[<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Shu_ECCV18.pdf">paper</a>][<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Shu_ECCV18.bib">bib</a>][<a href="https://github.com/zhixinshu/DeformingAutoencoders-pytorch">code</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project docunet  -->
	<div class="publication">
		<div class="thumb"><a href="http://www3.cs.stonybrook.edu/~cvl/docunet.html"><img src="./image/docunet.png"></a>&nbsp;</div>
		<div class="title"><a href="http://www3.cs.stonybrook.edu/~cvl/docunet.html">DocUNet: Document Image Unwarping via A Stacked U-Net</a></div>
		<div class="authors">
		Ke Ma,
		Zhixin Shu,
		Xue Bai,
		Jue Wang,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>CVPR 2018 </em>
		</div>
		<div class="cite">
		[<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Ma_CVPR18.pdf">paper</a>][<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2018/Ma_CVPR18.bib">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project dipface  -->
	<div class="publication">
		<div class="thumb"><a href="http://www3.cs.stonybrook.edu/~cvl/content/neuralface/neuralface.html"><img src="./image/neuralfaces.jpg"></a>&nbsp;</div>
		<div class="title"><a href="http://www3.cs.stonybrook.edu/~cvl/content/neuralface/neuralface.html">Neural Face Editing with Intrinsic Image Disentangling</a></div>
		<div class="authors">
		Zhixin Shu,
		Ersin Yumer,
		Sunil Hadap,
		Kalyan Sunkavalli,
		Eli Shechtman,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>CVPR 2017 (oral) </em>
		</div>
		<div class="cite">
		[<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2017/shu2017neuralface.pdf">paper</a>][<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2017/shu2017neuralface.bib">bib</a>][<a href="https://github.com/zhixinshu/NeuralFaceEditing">code</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	
	<!--project prl -->
	<div class="publication">
		<div class="thumb"><a href="http://www3.cs.stonybrook.edu/~cvl/content/portrait-relighting/prl.html"><img src="./image/prl.png"></a>&nbsp;</div>
		<div class="title"><a href="http://www3.cs.stonybrook.edu/~cvl/content/portrait-relighting/prl.html">Portrait Lighting Transfer using a Mass Transport Approach</a></div>
		<div class="authors">
		Zhixin Shu,
		Sunil Hadap,
		Eli Shechtman,
		Kalyan Sunkavalli,
		Sylvain Paris,
		Dimitris Samaras
		</div>
		<div class="venue">
		<em>TOG (presented at SIGGRAPH) 2017</em>
		</div>
		<div class="cite">
		[<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2017/shu_tog2017.pdf">paper</a>][<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2017/shu_tog2017.bib">bib</a>]
		</div>
		<br>
	</div>
	<!-- End of project -->

	<!-- project ews  -->
	<div class="publication">
		<div class="thumb"><a href="http://www3.cs.stonybrook.edu/~cvl/content/eyeopener/eyeopener.html"><img src="./image/ews.png"></a>&nbsp;</div>
		<div class="title"><a href="http://www3.cs.stonybrook.edu/~cvl/content/eyeopener/eyeopener.html">EyeOpener: Editing Eyes in the Wild</a></div>
		<div class="authors">
		Zhixin Shu,
		Eli Shechtman,
		Dimitris Samaras,
		Sunil Hadap
		</div>
		<div class="venue">
		<em>TOG (presented at SIGGRAPH) 2016 </em>
		</div>
		<div class="cite">
		[<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2016/eyeopener.pdf">paper</a>][<a href="http://www3.cs.stonybrook.edu/~cvl/content/papers/2016/eyeopener.bib">bib</a>]
		</div>
		<br>
	</div>

	<!-- End of project -->

	<div id="footer">
    &copy; All rights reserved
	</div>

 </div>



 <!-- Bootstrap core JavaScript
 ================================================== -->
 <!-- Placed at the end of the document so the pages load faster -->
 <script src="./style_files/jquery.min.js.download"></script>
 <script src="./style_files/bootstrap.min.js.download"></script>





</body></html>